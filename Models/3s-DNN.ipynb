{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "4kQGfDn2_KVc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "t1pgBT1Y_Nz8"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "W--LAXED_Pd5",
    "outputId": "2de2738b-4894-4d37-da0a-860661918c51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cpu'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "CDbxWNPh_RfR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "aUFrrn3wb90n"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Stall-Windows - Stall-3s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Stall', 'Quality', 'Time', 'CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
       "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
       "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
       "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
       "       'sMajority', 's25 P', 's50 P', 's75 P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "92TIYC4GcELK"
   },
   "outputs": [],
   "source": [
    "#df = df.replace([' ', '-',np.nan], 0) # There are null values\n",
    "df = df.replace([' ', '-',np.nan], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-A7wn3iex59",
    "outputId": "437aaf3b-8cab-4a35-b4c0-841ba0a322b8"
   },
   "outputs": [],
   "source": [
    "# Selective columns for mean calculation\n",
    "columns_to_convert = ['CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
    "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
    "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
    "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
    "       'sMajority', 's25 P', 's50 P', 's75 P']\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "\n",
    "# Replace np.nan with mean values for selective columns\n",
    "df[columns_to_convert] = df[columns_to_convert].fillna(df[columns_to_convert].mean())\n",
    "\n",
    "# Display the modified DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwMle4VXvOar",
    "outputId": "491a7180-6ba0-4c1d-bf37-872ecdc46cdb"
   },
   "outputs": [],
   "source": [
    "# Check which columns contain np.nan values\n",
    "columns_with_nan = df.isna().any()\n",
    "# Display the columns with np.nan values\n",
    "# print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "jsFpaDR4c0GH"
   },
   "outputs": [],
   "source": [
    "df['Stall'].replace('Yes', 1, inplace=True)\n",
    "df['Stall'].replace('No', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMZvSleecToT",
    "outputId": "f254df4a-a065-4c86-be47-782375572d1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Stall', 'Quality', 'Time', 'CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
       "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
       "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
       "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
       "       'sMajority', 's25 P', 's50 P', 's75 P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "KqZiOAnEcFNy"
   },
   "outputs": [],
   "source": [
    "X = df[['CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
    "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
    "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
    "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
    "       'sMajority', 's25 P', 's50 P', 's75 P']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "0Uz-Lf3ycYcM"
   },
   "outputs": [],
   "source": [
    "y =df['Stall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPGxzwbi1dSF",
    "outputId": "2a28d06c-3215-468e-92ea-012fb5ed38c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4393, 29), (4393,))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "Fbj2trSTd_61"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "iCFjyyRnc4e-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "89vPLfwEM_PP"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6856, 29)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "gkOL3bMlNdOP"
   },
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float32)\n",
    "y = torch.from_numpy(y).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxNRza7idOxY",
    "outputId": "45fde421-73b6-43d4-e191-39306f0f34b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6856, 29])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4045,  1.3930, -0.8155,  2.2628,  1.3959,  0.5140,  1.3079,  1.1926,\n",
       "        -0.4065, -0.3873, -0.3841, -0.3863, -0.3566, -0.3823, -0.4172,  0.8875,\n",
       "        -0.5047, -0.5005, -0.5074, -0.4656, -0.5275,  0.0740,  0.7399,  0.9711,\n",
       "         0.9757,  0.9732,  0.9451,  0.9883,  0.9464])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCvEQdyuliPn",
    "outputId": "71665074-9ea5-4219-d6ae-596045dcb7ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6856])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8gv73lHloJ_",
    "outputId": "0a071a03-7dad-41f5-d5e8-456ed19231b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2205, -0.2119,  0.7936,  0.5628, -0.2132,  0.0630, -0.0654,  0.2309,\n",
       "          -0.0034,  0.0246, -0.1771,  0.0256, -0.1501, -0.0965, -0.1299, -2.1351,\n",
       "          -2.1247, -1.5803, -2.1267, -2.0247, -2.0560, -1.8691, -1.2545, -1.1988,\n",
       "          -1.1523, -1.1997, -1.1654, -1.1530, -1.1706]]),\n",
       " torch.Size([1, 29]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42\n",
    ")\n",
    "\n",
    "X_train[:1],X_train[:1].shape, y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-RX--XqwmgWm",
    "outputId": "18cb29c8-8817-4c95-e7a3-b8ba6794bc9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4mOVimKl1Te",
    "outputId": "e2a7c8a4-5234-427b-a063-8b19bee1eecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InteruptionModel(\n",
      "  (layer_1): Linear(in_features=29, out_features=200, bias=True)\n",
      "  (layer_2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (layer_3): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build model with non-linear activation function\n",
    "from torch import nn\n",
    "class InteruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Intersperse the ReLU activation function between layers\n",
    "       return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "model_3 = InteruptionModel().to(device)\n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "Klsrww6wmhnp"
   },
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_3.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "LQsS4A83m2_j"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmgM-bVvmpqO",
    "outputId": "49ff5a25-a0d7-4b07-b116-9739dbacb247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.69241, Accuracy: 51.04% | Test Loss: 0.69078, Test Accuracy: 52.19%\n",
      "Epoch: 500 | Loss: 0.47805, Accuracy: 77.17% | Test Loss: 0.47283, Test Accuracy: 78.94%\n",
      "Epoch: 1000 | Loss: 0.37200, Accuracy: 84.77% | Test Loss: 0.40628, Test Accuracy: 82.36%\n",
      "Epoch: 1500 | Loss: 0.27046, Accuracy: 89.72% | Test Loss: 0.35737, Test Accuracy: 84.62%\n",
      "Epoch: 2000 | Loss: 0.18871, Accuracy: 93.65% | Test Loss: 0.33370, Test Accuracy: 85.64%\n",
      "Epoch: 2500 | Loss: 0.13691, Accuracy: 95.46% | Test Loss: 0.33845, Test Accuracy: 87.03%\n",
      "Epoch: 3000 | Loss: 0.10266, Accuracy: 97.05% | Test Loss: 0.35601, Test Accuracy: 88.56%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "epochs = 3500\n",
    "\n",
    "# Put all data on target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_3(X_train).squeeze()\n",
    "\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_3.eval()\n",
    "    with torch.no_grad():\n",
    "      # 1. Forward pass\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "        #print(test_logits.shape)\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "        # 2. Calcuate loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                             y_pred=test_pred)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "f0ajvarorOFf"
   },
   "outputs": [],
   "source": [
    "model_3.eval()\n",
    "with torch.no_grad():\n",
    "     y_preds = torch.round(torch.sigmoid(model_3(X_test))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoflm9NgrrrZ",
    "outputId": "e9d37db3-b51c-4554-8ca1-f247e5abdf47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1372]), torch.Size([1372]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "COMEFsAjrs7g"
   },
   "outputs": [],
   "source": [
    "predictions = y_preds.cpu().numpy() #if it is cuda, then this, otherwise y_pred.numpy()\n",
    "true_labels = y_test.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxDeucCxs6U8",
    "outputId": "76298050-eaf2-4bfe-e7cf-e8ca0ff5742a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[592  95]\n",
      " [ 59 626]]\n",
      "\n",
      "\n",
      "=== Score ===\n",
      "Accuracy: 0.887755\n",
      "Precision: 0.888834\n",
      "Recall: 0.887755\n",
      "Micro F1 score: 0.887755\n",
      "Macro F1 score: 0.887686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,fbeta_score\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Score ===\")\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "precision = precision_score(true_labels,  predictions, average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "microf1 = f1_score(true_labels, predictions, average='micro')\n",
    "print('Micro F1 score: %f' % microf1)\n",
    "macrof1 = f1_score(true_labels, predictions, average='macro')\n",
    "print('Macro F1 score: %f' % macrof1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACAmFpC-tJ0o",
    "outputId": "c6490a3b-e039-49e0-b033-90ae69cb71c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No-Stall       0.91      0.86      0.88       687\n",
      "       Stall       0.87      0.91      0.89       685\n",
      "\n",
      "    accuracy                           0.89      1372\n",
      "   macro avg       0.89      0.89      0.89      1372\n",
      "weighted avg       0.89      0.89      0.89      1372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['No-Stall', 'Stall']\n",
    "# Print precision-recall report\n",
    "print(classification_report(true_labels, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNsSYjD2tSlO"
   },
   "outputs": [],
   "source": [
    "#Done"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
